{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gsyt7\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda2\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input --> Raw Tweets in json\n",
    "# Output ---> Clea & structured tweets in Pandas Dataframe\n",
    "\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Structure the data by extracting the following data into columns: id_str, created_at, \n",
    "# lang, location, city, country, coordinates, text\n",
    "\n",
    "tweets_data_path = 'D:/Godfred_Files/Data_Files/Twitter_Data/Election2016/Raw_Data/PotusDebate1.txt' \n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['Tweet_ID'] = map(lambda tweet: tweet.get('id_str', None),tweets_data)\n",
    "tweets['Tweet_time'] = map(lambda tweet: tweet.get('created_at', None),tweets_data)\n",
    "tweets['Language'] = map(lambda tweet: tweet.get('lang', None),tweets_data)\n",
    "tweets['Text'] = map(lambda tweet: tweet.get('text', None),tweets_data)\n",
    "\n",
    "tweets['User_ID'] = [tweet['user']['id_str']if \"user\" in tweet and tweet['user'] else np.nan for tweet in tweets_data ]\n",
    "\n",
    "\n",
    "#tweets['City'] = [tweet['place']['name']if \"place\" in tweet and tweet['place'] else np.nan for tweet in tweets_data ]\n",
    "\n",
    "\n",
    "tweets['CityState'] = [tweet['place']['full_name']if \"place\" in tweet and tweet['place'] else np.nan for tweet in tweets_data ]\n",
    "\n",
    "tweets['Country'] = [tweet['place']['country_code']if \"place\" in tweet and tweet['place'] else np.nan for tweet in tweets_data ]\n",
    "\n",
    "\n",
    "splitCS = lambda x: pd.Series([i for i in reversed(x.split(','))])\n",
    "CS = tweets['CityState'].apply(splitCS)\n",
    "\n",
    "\n",
    "CS.rename(columns={1:'City',0:'State'},inplace=True)\n",
    "\n",
    "\n",
    "tweets['City'] = CS['City']\n",
    "\n",
    "\n",
    "tweets['State'] = CS['State']\n",
    "\n",
    "tweetdata = pd.DataFrame()\n",
    "\n",
    "tweetdata['User_ID'] = tweets['User_ID']\n",
    "tweetdata['Tweet_time'] = tweets['Tweet_time']\n",
    "tweetdata['Tweet_ID'] = tweets['Tweet_ID']\n",
    "tweetdata['Language'] = tweets['Language']\n",
    "tweetdata['City'] = tweets['City']\n",
    "tweetdata['State'] = tweets['State']\n",
    "tweetdata['Country'] = tweets['Country']\n",
    "tweetdata['Tweet'] = tweets['Text']\n",
    "\n",
    "# Write the \"tweets\" data to a csv file\n",
    "tweetdata.to_csv(\"D:/Godfred_Files/Data_Files/Twitter_Data/Election2016/Raw_Data/Debate1_full.csv\", sep= \" \", encoding='utf-8', columns=('User_ID','Tweet_time','Tweet_ID','Language','City','State','Country','Tweet'))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
